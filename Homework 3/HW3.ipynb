{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "806111cc",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> CSCI 544 - Applied Natural Language Processing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22154d15",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">CSCI 544 - Assignment 3</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9469d14",
   "metadata": {},
   "source": [
    "<h2>Name: Sri Manvith Vaddeboyina</h2>\n",
    "<h2>USC ID: 1231409457</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9dba61",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dff691",
   "metadata": {},
   "source": [
    "# 1. Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f36c1bf",
   "metadata": {},
   "source": [
    "<b>Importing necessary libraries/packages</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a45847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import contractions\n",
    "import tensorflow as tf\n",
    "from gensim import models\n",
    "from bs4 import BeautifulSoup\n",
    "import gensim.downloader as api\n",
    "from sklearn.svm import LinearSVC\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee1a38",
   "metadata": {},
   "source": [
    "<b>Read Data</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff27e78b",
   "metadata": {},
   "source": [
    "Reading Amazon US Beauty Reviews (tsv) dataset and retaining only the following two columns: <br>\n",
    "<b>1. review_body</b> <br>\n",
    "<b>2. star_rating</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c0d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.tsv', on_bad_lines = 'skip', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa281651",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['review_body','star_rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88770600",
   "metadata": {},
   "source": [
    "<b>Dropping the entire rows where any of the column contains NA value</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "808e5bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d4843",
   "metadata": {},
   "source": [
    "<b>Keep Reviews and Ratings</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e9178",
   "metadata": {},
   "source": [
    "<p>Create a three-class classification problem according to the ratings.</p>\n",
    "<b>Ratings:</b><br>\n",
    "<b>1 and 2 - class 1</b><br>\n",
    "<b>3 - class 2</b><br>\n",
    "<b>4 and 5 - class 3</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56ab9c10",
   "metadata": {},
   "outputs": [],
   "source": [
    " df = df[\n",
    "         df['star_rating'].eq('1') | \n",
    "         df['star_rating'].eq('2') | \n",
    "         df['star_rating'].eq('3') | \n",
    "         df['star_rating'].eq('4') | \n",
    "         df['star_rating'].eq('5')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc607af",
   "metadata": {},
   "source": [
    "<b>Verifying the datatype of each column and setting them correctly</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5200b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['star_rating']=df['star_rating'].astype(int)\n",
    "df['review_body']=df['review_body'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed99682c",
   "metadata": {},
   "source": [
    "<b>Creating a 3-class classification on ratings</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "210e4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition(x):\n",
    "    if x==1 or x==2:\n",
    "        return 1\n",
    "    elif x==3:\n",
    "        return 2\n",
    "    elif x==4 or x==5:\n",
    "        return 3\n",
    "    \n",
    "df['rating'] = df['star_rating'].apply(condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b193c37a",
   "metadata": {},
   "source": [
    "<b>We form three classes and select 20000 reviews randomly from each class.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb17c37",
   "metadata": {},
   "source": [
    "<b>Randomly selecting 20000 reviews from each of class 1,2 and 3.</b><br>\n",
    "<b>Total: 60000 reviews</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10d9cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.groupby('rating').sample(n=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d18e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['star_rating'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e665fbe",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2569ab",
   "metadata": {},
   "source": [
    "<b>Data Cleaning<b>\n",
    "<b> Removing the following as part of data cleaning:</b><br>\n",
    "<b>1. URLs</b><br>\n",
    "<b>2. HTML tags</b><br>\n",
    "<b>2. Contractions Expansion</b><br>\n",
    "<b>3. Non-alphabetic characters</b><br>\n",
    "<b>4. Converting text to lower case</b><br>\n",
    "<b>5. Removing extra spaces</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99395ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(texts):\n",
    "    return texts.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ff11027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(texts):\n",
    "    regex = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    cleantext = re.sub(regex, '', texts)\n",
    "    \n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe118724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(texts):\n",
    "    regex = re.compile('http\\S+')\n",
    "    cleantext = re.sub(regex, '', texts)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "510cb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_alphabetical(texts):\n",
    "    regex = re.compile('[^a-zA-Z]') \n",
    "    cleantext = re.sub(regex, ' ', texts)\n",
    "\n",
    "    regex = re.compile('_')\n",
    "    cleantext = re.sub(regex, ' ', cleantext)\n",
    "    \n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ecdb830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_spaces(texts):\n",
    "    regex = re.compile('[\\s]{2,}')\n",
    "    cleantext = re.sub(regex, ' ', texts)\n",
    "    \n",
    "    return cleantext.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9edf6881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contractionfunction(text):\n",
    "    expanded_words = []\n",
    "    for word in text.split():\n",
    "        # using contractions.fix to expand the shotened words\n",
    "        expanded_words.append(contractions.fix(word))\n",
    "        \n",
    "    expanded_words = ' '.join(expanded_words)\n",
    "    return expanded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9387dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_contractions(texts):\n",
    "    expended_corpus = []\n",
    "    for text in texts: \n",
    "        expended_corpus.append(contractionfunction(text))\n",
    "    return expended_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "980ffe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_body = df.copy(deep = True).review_body.tolist() \n",
    "labels = df.copy(deep = True).rating.tolist() \n",
    "clean_review_body = []\n",
    "\n",
    "for index , sen in enumerate(review_body):\n",
    "    sen = lower_case(sen)\n",
    "    sen = cleanhtml(sen)\n",
    "    sen = remove_url(sen)\n",
    "    sen = contractionfunction(sen)\n",
    "    sen = non_alphabetical(sen)\n",
    "    sen = extra_spaces(sen)\n",
    "    clean_review_body.append(sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ef021",
   "metadata": {},
   "source": [
    "<b>Cleaning data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b176d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = clean_review_body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b6404",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3454d8b0",
   "metadata": {},
   "source": [
    "# 2. Word Embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5d5584",
   "metadata": {},
   "source": [
    "# (a) word2vec-google-news-300 Word2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030b9d59",
   "metadata": {},
   "source": [
    "<b>Loading the pretrained \"word2vec-google-news-300\" Word2Vec model from gensim library.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31c3fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_news_word2vec = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee70a0c",
   "metadata": {},
   "source": [
    "<b>Checking the semantic similarity of example words</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cb0ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('queen', 0.7118193507194519)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_word2vec.most_similar(positive=[\"king\",\"woman\"],negative=[\"man\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c45abc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for: [good, better] :  0.6120729\n",
      "Similarity for: [neat, clean] :  0.29077712\n",
      "Similarity for: [big, huge] :  0.7809856\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity for: [good, better] : \", google_news_word2vec.similarity(w1=\"good\", w2=\"better\"))\n",
    "print(\"Similarity for: [neat, clean] : \", google_news_word2vec.similarity(w1=\"neat\", w2=\"clean\"))\n",
    "print(\"Similarity for: [big, huge] : \", google_news_word2vec.similarity(w1=\"big\", w2=\"huge\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546b9d8",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d41268",
   "metadata": {},
   "source": [
    "# (b) Train a Word2Vec model using your own dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008ed1d",
   "metadata": {},
   "source": [
    "<b>Training a Word2Vec model using amazon reviews dataset. Generating the tokens and training the word2vec model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71c79a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews_tokens(reviews):\n",
    "    reviews_tokens = []\n",
    "    for rev in reviews:\n",
    "        reviews_tokens.append(rev.split(\" \"))\n",
    "    return reviews_tokens\n",
    "reviews_tokens = get_reviews_tokens(df['clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804fd6ac",
   "metadata": {},
   "source": [
    "<b>Training a word2vec model with a embedding size as 300, window size as 13 and min word count as 9</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "668c43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(sentences = reviews_tokens, vector_size = 300, window = 13, min_count = 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a603e1e",
   "metadata": {},
   "source": [
    "<b>Checking the semantic similarity of example words</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd830ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for: [good, better] :  0.35388795\n",
      "Similarity for: [neat, clean] :  0.19055185\n",
      "Similarity for: [big, huge] :  0.61514467\n"
     ]
    }
   ],
   "source": [
    "w1 = word2vec.wv[\"good\"]\n",
    "w2 = word2vec.wv[\"better\"]\n",
    "print(\"Similarity for: [good, better] : \", cosine_similarity(w1.reshape(1,-1),w2.reshape(1,-1))[0][0])\n",
    "\n",
    "w3 = word2vec.wv[\"neat\"]\n",
    "w4 = word2vec.wv[\"clean\"]\n",
    "print(\"Similarity for: [neat, clean] : \", cosine_similarity(w3.reshape(1,-1),w4.reshape(1,-1))[0][0])\n",
    "\n",
    "w5 = word2vec.wv[\"big\"]\n",
    "w6 = word2vec.wv[\"huge\"]\n",
    "print(\"Similarity for: [big, huge] : \", cosine_similarity(w5.reshape(1,-1),w6.reshape(1,-1))[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d34a05",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a532e69",
   "metadata": {},
   "source": [
    "<b>What do you conclude from comparing vectors generated by yourself and the pretrained model? Which of the Word2Vec models seems to encode semantic similarities between words better?</b>\n",
    "\n",
    "<b>Reasoning:</b><br>\n",
    "The pretrained word2vec model performed well as compared to the custom trained word2vec model.  The reason could be:\n",
    "\n",
    "Pretrained models have been trained on very large datasets, which allow them to capture a wider range of relationships between words. This makes them more effective at capturing the subtle nuances of language. They have been trained on a diverse range of text data, which makes them more robust and adaptable to different contexts and domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895e0e1",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea9f9a2",
   "metadata": {},
   "source": [
    "# 3. Simple models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d040a",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda3b36c",
   "metadata": {},
   "source": [
    "<b>Splitting data into train and test splits 80:20 to be fed for TF-IDF</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "718e3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['rating'], test_size=0.20, random_state=42, stratify = df['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b770d8",
   "metadata": {},
   "source": [
    "<b>TF-IDF (term frequency-inverse document frequency) is a statistical measure that evaluates how relevant a word is to a document in a collection of documents.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6373a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,4))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "y_train_tfidf = y_train\n",
    "y_test_tfidf = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d8714",
   "metadata": {},
   "source": [
    "<h3>Perceptron</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61caef7",
   "metadata": {},
   "source": [
    "<b>Perceptron is a single layer neural network that does certain computations to detect features or business intelligence in the input data.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c3d52eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Perceptron on TF-IDF data :  0.7114166666666667\n"
     ]
    }
   ],
   "source": [
    "perceptron_text_clf = Perceptron()\n",
    "perceptron_text_clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "perceptron_predictions = perceptron_text_clf.predict(X_test_tfidf)\n",
    "perceptron_accuracy_tfidf = accuracy_score(y_test_tfidf, perceptron_predictions)\n",
    "print(\"Accuracy of Perceptron on TF-IDF data : \", perceptron_accuracy_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed50504",
   "metadata": {},
   "source": [
    "<h3>SVM</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7885937d",
   "metadata": {},
   "source": [
    "<b>The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N — the number of features) that distinctly classifies the data points.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac09178c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM on TF-IDF data :  0.7431666666666666\n"
     ]
    }
   ],
   "source": [
    "svc_text_clf = LinearSVC()\n",
    "svc_text_clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "svc_predictions = svc_text_clf.predict(X_test_tfidf)\n",
    "svc_accuarcy_tfidf = accuracy_score(y_test_tfidf, svc_predictions)\n",
    "print(\"Accuracy of SVM on TF-IDF data : \", svc_accuarcy_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca4a543",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e2d7df",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a62523bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the word embeddings for a sentence\n",
    "def get_review_embedding(data):\n",
    "    words = data.split(\" \")\n",
    "    embeddings = np.array([google_news_word2vec[word] for word in words if word in google_news_word2vec])\n",
    "    if embeddings.size == 0:\n",
    "        return np.zeros(300)\n",
    "    return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9087cc55",
   "metadata": {},
   "source": [
    "<b>Creating the train and test data using the get_review_embedding() function. This data is fed to Perceptron and SVM models</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f58cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the get_sentence_vector function to each sentence in the X_train_df dataframe\n",
    "train_review_vectors = [get_review_embedding(sentence) for sentence in X_train]\n",
    "\n",
    "# Stack the resulting vectors into a 2D numpy array\n",
    "X_train_w2v = np.stack(train_review_vectors, axis=0)\n",
    "\n",
    "test_review_vectors = [get_review_embedding(sentence) for sentence in X_test]\n",
    "\n",
    "# Stack the resulting vectors into a 2D numpy array\n",
    "X_test_w2v = np.stack(test_review_vectors, axis=0)\n",
    "y_train_w2v = y_train\n",
    "y_test_w2v = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915970f",
   "metadata": {},
   "source": [
    "<h3>Perceptron</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae32a91",
   "metadata": {},
   "source": [
    "<b>Perceptron is a single layer neural network that does certain computations to detect features or business intelligence in the input data.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0a76a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Perceptron on Word2Vec data :  0.5465\n"
     ]
    }
   ],
   "source": [
    "perceptron_text_clf = Perceptron()\n",
    "perceptron_text_clf.fit(X_train_w2v, y_train_w2v)\n",
    "perceptron_predictions = perceptron_text_clf.predict(X_test_w2v)\n",
    "perceptron_accuracy_w2v = accuracy_score(y_test_w2v, perceptron_predictions)\n",
    "print(\"Accuracy of Perceptron on Word2Vec data : \", perceptron_accuracy_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88beeef",
   "metadata": {},
   "source": [
    "<h3>SVM</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70b02d8",
   "metadata": {},
   "source": [
    "<b>The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N — the number of features) that distinctly classifies the data points.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7567e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM on Word2Vec data :  0.6711666666666667\n"
     ]
    }
   ],
   "source": [
    "svc_text_clf = LinearSVC()\n",
    "svc_text_clf.fit(X_train_w2v, y_train_w2v)\n",
    "svc_predictions = svc_text_clf.predict(X_test_w2v)\n",
    "svc_accuracy_w2v = accuracy_score(y_test_w2v, svc_predictions)\n",
    "print(\"Accuracy of SVM on Word2Vec data : \", svc_accuracy_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0135af66",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126e101c",
   "metadata": {},
   "source": [
    "<b>What do you conclude from comparing performances for the models trained using the two different feature types (TF-IDF and your trained Word2Vec features)?</b><br><br>\n",
    "<b>Reasoning:</b><br>\n",
    "Between the TF-IDF and google pretrained Word2Vec accuracies on Perceptron and SVM, the accuracies of TF-IDF are better compared to pretrained Word2Vec. Reason could be that:\n",
    "While Word2Vec is a powerful technique for capturing semantic and syntactic relationships between words, TF-IDF may be more appropriate for certain tasks that rely on keyword matching or text classification. In our current use-case, it is the lexical similarity that plays a greater role than the semantic similarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f185c",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9635141",
   "metadata": {},
   "source": [
    "# 4. Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9900d7",
   "metadata": {},
   "source": [
    "# (a) FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c1120",
   "metadata": {},
   "source": [
    "<b>A Feed Forward Neural Network is an artificial neural network in which the connections between nodes does not form a cycle. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71638e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_w2v = np.array(y_train_w2v)\n",
    "y_test_w2v = np.array(y_test_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6934430",
   "metadata": {},
   "source": [
    "<b>Feed forward Neural Network code with two hidden layers, each with 100 and 10 nodes, respectively. relu and softmax activation is used in the code and \"y values-1\" is taken to have class labels as 0, 1, 2 instead of 1, 2, 3</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72cd499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FNN(x_train, y_train, x_test, y_test, num_features, epochs, batch_size, learning_rate_val):\n",
    "    model_fnn = tf.keras.Sequential(\n",
    "                                    [   tf.keras.layers.InputLayer((num_features,)),\n",
    "                                        tf.keras.layers.Dense(100,activation='relu'),\n",
    "                                        tf.keras.layers.Dense(10,activation='relu'),\n",
    "                                        tf.keras.layers.Dense(3,activation='softmax')\n",
    "                                    ]\n",
    "                                )\n",
    "\n",
    "    model_fnn.compile(\n",
    "                    optimizer = Adam(learning_rate=learning_rate_val),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "    print(model_fnn.summary())\n",
    "\n",
    "    model_fnn.fit(x_train,y_train-1, batch_size = batch_size, epochs = epochs)\n",
    "\n",
    "    result = model_fnn.evaluate(x_test,y_test-1)\n",
    "    return result[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb470677",
   "metadata": {},
   "source": [
    "<b>Passing the num_features, epochs, batch size and learning rate parameters to the FNN function</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9fe039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,143\n",
      "Trainable params: 31,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 20:37:34.634487: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-03-01 20:37:34.634526: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-01 20:37:34.634549: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nlp): /proc/driver/nvidia/version does not exist\n",
      "2023-03-01 20:37:34.634885: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 2s 2ms/step - loss: 0.8445 - accuracy: 0.5930\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.7510 - accuracy: 0.6677\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.7295 - accuracy: 0.6783\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.7170 - accuracy: 0.6851\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.7064 - accuracy: 0.6913\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6968 - accuracy: 0.6959\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6891 - accuracy: 0.6991\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6812 - accuracy: 0.7022\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6758 - accuracy: 0.7060\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6686 - accuracy: 0.7092\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6618 - accuracy: 0.7128\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6561 - accuracy: 0.7156\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6500 - accuracy: 0.7175\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6447 - accuracy: 0.7204\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6394 - accuracy: 0.7228\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6341 - accuracy: 0.7254\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6277 - accuracy: 0.7284\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6222 - accuracy: 0.7309\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6179 - accuracy: 0.7331\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6120 - accuracy: 0.7364\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6077 - accuracy: 0.7373\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.6041 - accuracy: 0.7396\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.7414\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.7455\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5887 - accuracy: 0.7479\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5845 - accuracy: 0.7498\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.7518\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5757 - accuracy: 0.7542\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5718 - accuracy: 0.7571\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7598\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5617 - accuracy: 0.7616\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5575 - accuracy: 0.7619\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5546 - accuracy: 0.7652\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5490 - accuracy: 0.7668\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7693\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7737\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7739\n",
      "Epoch 38/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7756\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7753\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5251 - accuracy: 0.7797\n",
      "Epoch 41/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5216 - accuracy: 0.7819\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7832\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5137 - accuracy: 0.7850\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5098 - accuracy: 0.7856\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7882\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5021 - accuracy: 0.7907\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.5001 - accuracy: 0.7906\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4968 - accuracy: 0.7929\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4921 - accuracy: 0.7974\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4894 - accuracy: 0.7961\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.8172 - accuracy: 0.6727\n"
     ]
    }
   ],
   "source": [
    "fnn_accuracy = FNN(X_train_w2v, y_train_w2v, X_test_w2v, y_test_w2v, 300, 50, 64,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45557921-ea91-4ed6-b27a-9b7497ca2684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of FNN model:  0.6727499961853027\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of FNN model: \",fnn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5cdfb8",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f8682",
   "metadata": {},
   "source": [
    "# (b) Top 10 FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd2462",
   "metadata": {},
   "source": [
    "<b>Concatenate the first 10 Word2Vec vectors for each review. Padding 0 values to the vectors if there is no sufficient review length</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fbb6434-d83f-4447-ba6b-afa8e075172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_top10(reviews):\n",
    "    top10_embeddings=[]\n",
    "    count = 0\n",
    "\n",
    "    for word in reviews.split(\" \"):\n",
    "        if word in google_news_word2vec:\n",
    "            count = count + 1\n",
    "            if count > 10:\n",
    "                break\n",
    "            else:\n",
    "                word_embedding = google_news_word2vec[word]\n",
    "                top10_embeddings.extend(word_embedding)\n",
    "                \n",
    "    length = len(top10_embeddings)            \n",
    "    if length == 0:\n",
    "        return np.zeros(3000)\n",
    "    \n",
    "    if length < 3000:\n",
    "        less = 3000 - length\n",
    "        top10_embeddings += less * [0]\n",
    "\n",
    "    return top10_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b8ae988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the get_sentence_vector function to each sentence in the X_train_df dataframe\n",
    "train_top10_review_vectors = X_train.apply(get_review_top10)\n",
    "\n",
    "# Stack the resulting vectors into a 2D numpy array\n",
    "X_train_top10_w2v = np.stack(train_top10_review_vectors, axis=0)\n",
    "\n",
    "test_top10_review_vectors = X_test.apply(get_review_top10)\n",
    "\n",
    "# Stack the resulting vectors into a 2D numpy array\n",
    "X_test_top10_w2v = np.stack(test_top10_review_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6d51803",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 100)               300100    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301,143\n",
      "Trainable params: 301,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.8462 - accuracy: 0.6017\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.7528 - accuracy: 0.6595\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.6834 - accuracy: 0.6996\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.5994 - accuracy: 0.7458\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.5011 - accuracy: 0.7926\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.4010 - accuracy: 0.8405\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.3152 - accuracy: 0.8798\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.2459 - accuracy: 0.9083\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.1983 - accuracy: 0.9288\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1648 - accuracy: 0.9416\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1409 - accuracy: 0.9496\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.1320 - accuracy: 0.9516\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.1233 - accuracy: 0.9562\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.1093 - accuracy: 0.9617\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.1045 - accuracy: 0.9632\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1039 - accuracy: 0.9629\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0939 - accuracy: 0.9664\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0910 - accuracy: 0.9668\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0994 - accuracy: 0.9644\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0886 - accuracy: 0.9679\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0758 - accuracy: 0.9720\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.9694\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0837 - accuracy: 0.9704\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0793 - accuracy: 0.9706\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0743 - accuracy: 0.9721\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0813 - accuracy: 0.9698\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0736 - accuracy: 0.9732\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0781 - accuracy: 0.9712\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0701 - accuracy: 0.9743\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0722 - accuracy: 0.9730\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0815 - accuracy: 0.9703\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0667 - accuracy: 0.9751\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0687 - accuracy: 0.9750\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0705 - accuracy: 0.9737\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0693 - accuracy: 0.9743\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0649 - accuracy: 0.9759\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0667 - accuracy: 0.9746\n",
      "Epoch 38/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0695 - accuracy: 0.9740\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0673 - accuracy: 0.9744\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0591 - accuracy: 0.9771\n",
      "Epoch 41/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0579 - accuracy: 0.9783\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0672 - accuracy: 0.9748\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0710 - accuracy: 0.9735\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0600 - accuracy: 0.9769\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0591 - accuracy: 0.9777\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0650 - accuracy: 0.9756\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0613 - accuracy: 0.9767\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0563 - accuracy: 0.9783\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0531 - accuracy: 0.9794\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0650 - accuracy: 0.9758\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 4.0429 - accuracy: 0.5889\n"
     ]
    }
   ],
   "source": [
    "fnn_top10_accuracy = FNN(X_train_top10_w2v, y_train_w2v, X_test_top10_w2v, y_test_w2v, 3000, 50, 64, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a293f99a-b6d3-4deb-b0ba-b471e046efe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Top 10 FNN model:  0.5889166593551636\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Top 10 FNN model: \",fnn_top10_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b174d25",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cc9528",
   "metadata": {},
   "source": [
    "<b>What do you conclude by comparing accuracy values you obtain with\n",
    "those obtained in the “’Simple Models” section.</b><br>\n",
    "\n",
    "<b> Reasoning:</b>\n",
    "\n",
    "The results obtained from simple models are slightly better than the FNN and top 10 FNN. There is a possibility of FNN giving better accuracies if we build a much more complex architecture. The FNN model that uses only the first 10 word embeddings concatenated to represent the entire review has poorer performance compared to the traditional FNN implementation and the simple models. \n",
    "\n",
    "The reasons for this poor performance: Just using the first 10 words may not be sufficient and concatenating word embeddings may not accurately capture the contextual semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea1cd94",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444cf3b",
   "metadata": {},
   "source": [
    "# 5. Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d3815",
   "metadata": {},
   "source": [
    "<b>Preparing data for RNN, GRU and LSTM code</b><br>\n",
    "<b>Limiting the maximum review length to 20 by truncating longer reviews and padding shorter reviews with a null value (0).</b><br>\n",
    "<b>Adding a random string value that is not present in word2vec model as part of padding if the length < 20 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0026179",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = []\n",
    "for sentence in X_train.tolist():\n",
    "    # Split the sentence by space and take the first 20 words\n",
    "    words = sentence.split(' ')[:20]\n",
    "\n",
    "    # Pad the rest with random_word if the sentence is less than 20 words\n",
    "    words += ['random_word'] * (20 - len(words))\n",
    "\n",
    "    # Replace each word with its corresponding vector or the default vector\n",
    "    vectorized_words = []\n",
    "    for word in words:\n",
    "        if word in google_news_word2vec:\n",
    "            vectorized_words.append(google_news_word2vec[word])\n",
    "        else:\n",
    "            vectorized_words.append(np.zeros((300,)))\n",
    "\n",
    "    # Append the processed sentence to the output array\n",
    "    X_train_processed.append(vectorized_words)\n",
    "\n",
    "# Convert the output array to a numpy array\n",
    "X_train = np.array(X_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1b18a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process X_train\n",
    "X_test_processed = []\n",
    "for sentence in X_test.tolist():\n",
    "    # Split the sentence by space and take the first 20 words\n",
    "    words = sentence.split(' ')[:20]\n",
    "\n",
    "    # Pad the rest with random_word if the sentence is less than 20 words\n",
    "    words += ['random_word'] * (20 - len(words))\n",
    "\n",
    "    # Replace each word with its corresponding vector or the default vector\n",
    "    vectorized_words = []\n",
    "    for word in words:\n",
    "        if word in google_news_word2vec:\n",
    "            vectorized_words.append(google_news_word2vec[word])\n",
    "        else:\n",
    "            vectorized_words.append(np.zeros((300,)))\n",
    "\n",
    "    # Append the processed sentence to the output array\n",
    "    X_test_processed.append(vectorized_words)\n",
    "\n",
    "# Convert the output array to a numpy array\n",
    "X_test = np.array(X_test_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce3494",
   "metadata": {},
   "source": [
    "# (a) Simple RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb408328",
   "metadata": {},
   "source": [
    "RNN works on the principle of saving the output of a particular layer and feeding this back to the input in order to predict the output of the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9390ebe2",
   "metadata": {},
   "source": [
    "<b>RNN code with input layer dimensions of (20,300) and 1 SimpleRNN layer with hidden state size of 20. \"y values-1\" is taken to have class labels as 0, 1, 2 instead of 1, 2, 3</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd0842c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x_train, y_train, x_test, y_test, epochs, batch_size, learning_rate_val):\n",
    "    model_rnn = tf.keras.Sequential([ tf.keras.layers.InputLayer((20,300)),\n",
    "                                    tf.keras.layers.SimpleRNN(20),\n",
    "                                    tf.keras.layers.Dense(3,activation='softmax')])\n",
    "\n",
    "\n",
    "    model_rnn.compile (\n",
    "                        optimizer = Adam(learning_rate = learning_rate_val),\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy']\n",
    "                    )\n",
    "\n",
    "    print(model_rnn.summary())\n",
    "    \n",
    "    model_rnn.fit(x_train,y_train-1, batch_size = batch_size, epochs = epochs)\n",
    "    result = model_rnn.evaluate(x_test,y_test-1)\n",
    "    return result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5babf38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 20)                6420      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,483\n",
      "Trainable params: 6,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "750/750 [==============================] - 4s 4ms/step - loss: 0.9362 - accuracy: 0.5282\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.8074 - accuracy: 0.6369\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7865 - accuracy: 0.6488\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7748 - accuracy: 0.6524\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7668 - accuracy: 0.6559\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7613 - accuracy: 0.6589\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7570 - accuracy: 0.6606\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.7522 - accuracy: 0.6634\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7477 - accuracy: 0.6662\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7426 - accuracy: 0.6695\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7402 - accuracy: 0.6719\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7374 - accuracy: 0.6708\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7333 - accuracy: 0.6735\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7306 - accuracy: 0.6759\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7265 - accuracy: 0.6795\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7253 - accuracy: 0.6785\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7216 - accuracy: 0.6809\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7214 - accuracy: 0.6788\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7149 - accuracy: 0.6837\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7130 - accuracy: 0.6851\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7113 - accuracy: 0.6852\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7082 - accuracy: 0.6857\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7082 - accuracy: 0.6885\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7046 - accuracy: 0.6902\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7011 - accuracy: 0.6907\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6990 - accuracy: 0.6921\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.7003 - accuracy: 0.6938\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6954 - accuracy: 0.6950\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6957 - accuracy: 0.6944\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6942 - accuracy: 0.6963\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6905 - accuracy: 0.6979\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6901 - accuracy: 0.6969\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6866 - accuracy: 0.7010\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6849 - accuracy: 0.6991\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6833 - accuracy: 0.6993\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6817 - accuracy: 0.7028\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6796 - accuracy: 0.7031\n",
      "Epoch 38/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6790 - accuracy: 0.7032\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6778 - accuracy: 0.7035\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6763 - accuracy: 0.7047\n",
      "Epoch 41/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6768 - accuracy: 0.7054\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6748 - accuracy: 0.7057\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6743 - accuracy: 0.7074\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6733 - accuracy: 0.7082\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6709 - accuracy: 0.7069\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6718 - accuracy: 0.7082\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6685 - accuracy: 0.7092\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6681 - accuracy: 0.7106\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6684 - accuracy: 0.7087\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.6661 - accuracy: 0.7127\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8056 - accuracy: 0.6435\n"
     ]
    }
   ],
   "source": [
    "rnn_accuracy = RNN(X_train, y_train, X_test, y_test, 50, 64, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0541cbb9-c286-491b-84ee-660ddf1fa00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RNN model: 0.6434999704360962\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of RNN model:\",rnn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c71454",
   "metadata": {},
   "source": [
    "<P></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69faafc2",
   "metadata": {},
   "source": [
    "# (b) GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a12b2c",
   "metadata": {},
   "source": [
    "A gated recurrent unit (GRU) is part of a specific model of recurrent neural network that intends to use connections through a sequence of nodes to perform machine learning tasks associated with memory and clustering, for instance, in speech recognition. Gated recurrent units help to adjust neural network input weights to solve the vanishing gradient problem that is a common issue with recurrent neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c69b707",
   "metadata": {},
   "source": [
    "<b>GRU code with input layer dimensions of (20,300) and 1 GRU layer with hidden state size of 20. \"y values-1\" is taken to have class labels as 0, 1, 2 instead of 1, 2, 3</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "054fefa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU(x_train, y_train, x_test, y_test, epochs, batch_size, learning_rate_val):\n",
    "    model_gru = tf.keras.Sequential([ tf.keras.layers.InputLayer((20,300)),\n",
    "                                    tf.keras.layers.GRU(20),\n",
    "                                    tf.keras.layers.Dense(3,activation='softmax')])\n",
    "\n",
    "\n",
    "    model_gru.compile (\n",
    "                        optimizer = Adam(learning_rate = learning_rate_val),\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy']\n",
    "                    )\n",
    "\n",
    "    print(model_gru.summary())\n",
    "\n",
    "    model_gru.fit(x_train,y_train-1, batch_size = batch_size, epochs = epochs)\n",
    "\n",
    "    result = model_gru.evaluate(x_test,y_test-1)\n",
    "    return result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f23565e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 20)                19320     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,383\n",
      "Trainable params: 19,383\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.8849 - accuracy: 0.5584\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.7413 - accuracy: 0.6682\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.7127 - accuracy: 0.6820\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6931 - accuracy: 0.6933\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6808 - accuracy: 0.7004\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6696 - accuracy: 0.7063\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6603 - accuracy: 0.7119\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6503 - accuracy: 0.7169\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6430 - accuracy: 0.7196\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6372 - accuracy: 0.7223\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6306 - accuracy: 0.7265\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6243 - accuracy: 0.7283\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6196 - accuracy: 0.7308\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6130 - accuracy: 0.7341\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6073 - accuracy: 0.7387\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6035 - accuracy: 0.7396\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5986 - accuracy: 0.7418\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5938 - accuracy: 0.7442\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5894 - accuracy: 0.7472\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5841 - accuracy: 0.7488\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5806 - accuracy: 0.7513\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5768 - accuracy: 0.7515\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5717 - accuracy: 0.7547\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5685 - accuracy: 0.7567\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5646 - accuracy: 0.7586\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5601 - accuracy: 0.7610\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5555 - accuracy: 0.7621\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5527 - accuracy: 0.7644\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5482 - accuracy: 0.7669\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5459 - accuracy: 0.7674\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5422 - accuracy: 0.7686\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5390 - accuracy: 0.7718\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5347 - accuracy: 0.7735\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5311 - accuracy: 0.7747\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5283 - accuracy: 0.7753\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5244 - accuracy: 0.7793\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5215 - accuracy: 0.7802\n",
      "Epoch 38/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5183 - accuracy: 0.7800\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5140 - accuracy: 0.7823\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5123 - accuracy: 0.7833\n",
      "Epoch 41/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5100 - accuracy: 0.7850\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5055 - accuracy: 0.7875\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5012 - accuracy: 0.7896\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.4988 - accuracy: 0.7902\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.4960 - accuracy: 0.7921\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.4936 - accuracy: 0.7932\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.4897 - accuracy: 0.7958\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.4885 - accuracy: 0.7937\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.4856 - accuracy: 0.7971\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.4823 - accuracy: 0.7975\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8137 - accuracy: 0.6848\n"
     ]
    }
   ],
   "source": [
    "gru_accuracy = GRU(X_train, y_train, X_test, y_test, 50, 64, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f7450c4-ff9d-4277-a89e-15e97c14f7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GRU model: 0.6847500205039978\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of GRU model:\",gru_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf769a60",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc8ebf",
   "metadata": {},
   "source": [
    "# (c) LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d24845e",
   "metadata": {},
   "source": [
    "LSTM stands for long short-term memory networks, used in the field of Deep Learning. It is a variety of recurrent neural networks (RNNs) that are capable of learning long-term dependencies, especially in sequence prediction problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7919c53a",
   "metadata": {},
   "source": [
    "<b>LSTM code with input layer dimensions of (20,300) and 1 LSTM layer with hidden state size of 20. \"y values-1\" is taken to have class labels as 0, 1, 2 instead of 1, 2, 3</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81aff955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(x_train, y_train, x_test, y_test, epochs, batch_size, learning_rate_val):\n",
    "    model_lstm = tf.keras.Sequential([ tf.keras.layers.InputLayer((20,300)),\n",
    "                                    tf.keras.layers.LSTM(20),\n",
    "                                    tf.keras.layers.Dense(3,activation='softmax')])\n",
    "\n",
    "\n",
    "    model_lstm.compile (\n",
    "                        optimizer = Adam(learning_rate = learning_rate_val),\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy']\n",
    "                    )\n",
    "\n",
    "    print(model_lstm.summary())\n",
    "\n",
    "    model_lstm.fit(x_train,y_train-1, batch_size = batch_size, epochs = epochs)\n",
    "\n",
    "    result = model_lstm.evaluate(x_test,y_test-1)\n",
    "    return result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28885d1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 20)                25680     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,743\n",
      "Trainable params: 25,743\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "750/750 [==============================] - 7s 7ms/step - loss: 0.8411 - accuracy: 0.6051\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.7454 - accuracy: 0.6693\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.7193 - accuracy: 0.6808\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.7024 - accuracy: 0.6901\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.6875 - accuracy: 0.6961\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.6752 - accuracy: 0.7018\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.6628 - accuracy: 0.7084\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.6553 - accuracy: 0.7116\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.6441 - accuracy: 0.7160\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.6361 - accuracy: 0.7232\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.6276 - accuracy: 0.7269\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.6204 - accuracy: 0.7310\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.6132 - accuracy: 0.7344\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.6058 - accuracy: 0.7387\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.5985 - accuracy: 0.7423\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5943 - accuracy: 0.7437\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5884 - accuracy: 0.7468\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5808 - accuracy: 0.7508\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.5740 - accuracy: 0.7534\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5701 - accuracy: 0.7561\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5636 - accuracy: 0.7601\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.5587 - accuracy: 0.7633\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5541 - accuracy: 0.7644\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5485 - accuracy: 0.7668\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5447 - accuracy: 0.7706\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5382 - accuracy: 0.7728\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5330 - accuracy: 0.7746\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5276 - accuracy: 0.7782\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5256 - accuracy: 0.7791\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.5193 - accuracy: 0.7821\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5139 - accuracy: 0.7841\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5123 - accuracy: 0.7855\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5052 - accuracy: 0.7891\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.5022 - accuracy: 0.7905\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4972 - accuracy: 0.7945\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4946 - accuracy: 0.7943\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4899 - accuracy: 0.7968\n",
      "Epoch 38/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4857 - accuracy: 0.7992\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4813 - accuracy: 0.8008\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4782 - accuracy: 0.8019\n",
      "Epoch 41/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4744 - accuracy: 0.8045\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4704 - accuracy: 0.8065\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4657 - accuracy: 0.8070\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4626 - accuracy: 0.8101\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.4599 - accuracy: 0.8110\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 6s 9ms/step - loss: 0.4555 - accuracy: 0.8133\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 6s 9ms/step - loss: 0.4512 - accuracy: 0.8153\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.4473 - accuracy: 0.8171\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 6s 9ms/step - loss: 0.4472 - accuracy: 0.8187\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 6s 9ms/step - loss: 0.4437 - accuracy: 0.8205\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.8732 - accuracy: 0.6710\n"
     ]
    }
   ],
   "source": [
    "lstm_accuracy = LSTM(X_train, y_train, X_test, y_test, 50, 64, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "608054bc-a60e-4f68-a98d-238515cf2c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LSTM model: 0.6710000038146973\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of LSTM model:\",lstm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273c0c1-fd8e-4f66-ac51-72721e5b5507",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc2b8b-73cf-4f09-8360-53758a282746",
   "metadata": {},
   "source": [
    "<h3>Accuracy values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bdd5c1a5-0d9d-49f0-839f-bfe27ada74e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Perceptron on TF-IDF data :  0.7114166666666667\n",
      "Accuracy of SVM on TF-IDF data :  0.7431666666666666\n",
      "Accuracy of Perceptron on Word2Vec data :  0.5465\n",
      "Accuracy of SVM on Word2Vec data :  0.6711666666666667\n",
      "Accuracy of FNN model:  0.6727499961853027\n",
      "Accuracy of Top 10 FNN model:  0.5889166593551636\n",
      "Accuracy of RNN model: 0.6434999704360962\n",
      "Accuracy of GRU model: 0.6847500205039978\n",
      "Accuracy of LSTM model: 0.6710000038146973\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Perceptron on TF-IDF data : \", perceptron_accuracy_tfidf)\n",
    "print(\"Accuracy of SVM on TF-IDF data : \", svc_accuarcy_tfidf)\n",
    "print(\"Accuracy of Perceptron on Word2Vec data : \", perceptron_accuracy_w2v)\n",
    "print(\"Accuracy of SVM on Word2Vec data : \", svc_accuracy_w2v)\n",
    "print(\"Accuracy of FNN model: \",fnn_accuracy)\n",
    "print(\"Accuracy of Top 10 FNN model: \",fnn_top10_accuracy)\n",
    "print(\"Accuracy of RNN model:\",rnn_accuracy)\n",
    "print(\"Accuracy of GRU model:\",gru_accuracy)\n",
    "print(\"Accuracy of LSTM model:\",lstm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aade9e78",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe55afb",
   "metadata": {},
   "source": [
    "<b>What do you conclude by comparing accuracy values you obtain by GRU, LSTM, and Simple RNN.</b>\n",
    "\n",
    "<b>Reasoning:</b><br>\n",
    "The accuracy values of SimpleRNN, GRU and LSTM are in this order: LSTM >= GRU > SimpleRNN.\n",
    "The reason could be that it is common to observe that GRU and LSTM tend to outperform Simple RNN in tasks that require processing of long-term dependencies or maintaining memory over a longer period of time. This is because GRU and LSTM have more sophisticated gating mechanisms that allow them to selectively forget or store information in their memory cells, while Simple RNN lacks these mechanisms and is prone to the vanishing gradient problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0aed31",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Thank You</h3>"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
